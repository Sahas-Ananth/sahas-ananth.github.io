<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <!-- Google Fots -->
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap"
    rel="stylesheet" />
  <!-- Remixicon Icon -->
  <link href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" rel="stylesheet" />
  <!-- Remixicon Icon -->
  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

  <link href="https://unpkg.com/aos@2.3.1/dist/aos.css" rel="stylesheet" />
  <!-- Main CSS -->
  <link href="assets/css/main.css" rel="stylesheet" />
  <link rel="icon" type="image/png" href="assets/images/site_logo.png">
  <title>Sahasrajit Anantharamakrishnan Personal Website</title>
</head>

<body>
  <!-- header -->
  <header class="ds-header" id="site-header">
    <div class="container">
      <div class="ds-header-inner">
        <!-- logo -->
        <a href="index.html" class="ds-logo">
          <span><img src="assets/images/Dp_3.png" /></span>Sahasrajit Anantharamakrishnan
        </a>
        <!-- logo -->
        <!-- social -->
        <ul class="ds-social">
          <li>
            <a href="https://github.com/Sahas-Ananth" target="_blank">
              <i class="ri-github-fill"></i>
            </a>
          </li>
          <li>
            <a href="mailto:anantharamakrishn.sa@northeastern.edu" target="_blank"><i class="ri-mail-fill"></i></a>
          </li>
          <li>
            <a href="https://www.linkedin.com/in/sahas-ananth/" target="_blank"><i class="ri-linkedin-fill"></i></a>
          </li>
        </ul>
        <!-- social -->
      </div>
    </div>
  </header>
  <!-- header -->
  <!-- banner -->
  <div class="ds-banner">
    <div class="container">
      <div class="row">
        <div class="col-12 col-sm-12 col-md-5 col-lg-5 col-xl-5 col-xxl-5">
          <figure>
            <img src="assets/images/Dp_2.png" />
          </figure>
        </div>
        <div class="col-12 col-sm-12 col-md-7 col-lg-7 col-xl-7 col-xxl-7">
          <section>
            <h1>
              <span>HI THERE I AM</span>
              Sahasrajit Anantharamakrishnan
              <!-- Robotics Engineer + Master's Student. -->
            </h1>

            <div class="ds-button-sec mt-4">
              <a href="assets/pdfs/Sahasrajit Anantharamakrishnan Resume.pdf" target="_blank" class="ds-button">Download
                Resume</a>
            </div>
            <!-- <ul class="ds-numbervalulist"> -->
            <!--   <li> -->
            <!--     <strong>6+</strong> -->
            <!--     <span>Experience</span> -->
            <!--   </li> -->
            <!--   <li> -->
            <!--     <strong>89</strong> -->
            <!--     <span>Projects</span> -->
            <!--   </li> -->
            <!--   <li> -->
            <!--     <strong>52</strong> -->
            <!--     <span>Happy Clients</span> -->
            <!--   </li> -->
            <!-- </ul> -->
          </section>
        </div>
      </div>
    </div>
  </div>
  <!-- banner -->

  <!-- about -->
  <div class="ds-about-section">
    <div class="container">
      <section>
        <h2 class="ds-heading">About Me</h2>
        <p>
          I am a dedicated graduate student in the MS Robotics program at
          Northeastern University, deeply engaged in cutting-edge research at
          the
          <a class="ds-anchor" href="https://neu-autonomy.github.io/lab_website/" target="_blank">Northeastern Autonomy
            and Intelligence Laboratory</a>. Under the guidance of
          <a href="https://mfe7.github.io/" target="_blank" class="ds-anchor">Professor Michael Everett</a>, I am
          spearheading a groundbreaking project on High Speed Off-road
          Autonomy, striving for self-driving capability in challenging
          terrains with a focus on safety. My journey in robotics began at
          thirteen, sparking a passion that led me to pursue a B.E. in
          Electronics and Communication. From winning competitions to
          internships at Capgemini and RigBetal Labs, I have honed my skills
          in robotics, project management, and innovative problem-solving.
          Notably, my Road Anomaly Detection System (R.A.D.S.) algorithm,
          designed for cost-effective road anomaly detection, earned me a
          full-time job offer. I thrive on solving complex problems, love
          learning, and excel in collaborative environments. With a knack for
          quick and efficient learning, I am poised to make significant
          contributions to the field of robotics through my enthusiasm,
          skills, and commitment to innovation. Here is a (not so small)
          history of me:
        </p>
        <p>
          My fascination with robotics began at the age of thirteen when I
          participated in a summer robotics course. This experience exposed me
          to essential robotics concepts like Arduino programming, the theory
          and application of diverse sensors and actuators, and most
          importantly, ignited my enthusiasm to pursue a career as a robotics
          engineer.
        </p>
        <div class="collapse" id="aboutMe">
          <p>
            This ambition shaped my academic path. Recognizing robotics is an
            amalgamation of Electrical, Mechanical, and Computer Science
            Engineering, I opted for a B.E. in Electronics and Communication at
            Anna University, Chennai. This path provided crucial knowledge in
            Control Systems, Communication Networks, and Embedded Systems - all
            pivotal for robotics.
          </p>
          <p>
            In eighth grade, I engaged in robotics competitions at N.I.T.
            Calicut, sparking my passion. Despite setbacks, I learned crucial
            lessons in software and hardware optimization, leading to an 8.62%
            performance boost. This ignited the spark and love I have for
            competition and optimization. Freshman year in college I clinched
            victory at Roboprix 2019 held at V.I.T. Chennai in a high speed
            Robot racing competition.
          </p>
          <p>
            During the 2020 pandemic, I completed a 5-month internship at
            Capgemini as a Robotics Intern, focusing on a ROS-based AUGIR
            (Autonomous Ultraviolet Germicidal IRradiation) mobile robot. This
            experience enhanced my project management and leadership skills in
            corporate R&D. Using Fusion 360, we modeled the robot in URDF and
            simulated it in Gazebo, implementing SLAM algorithms for navigation.
            I developed a proprietary algorithm for sanitation, utilizing
            ray-casting to generate navigation waypoints for efficient cleaning.
            In a project that didn't explicitly demand such innovation, creating
            this algorithm showcased my ability to think outside the box and
            reinforced my commitment to developing innovative solutions,
            reducing my inclination to accept things as-is. Additionally, this
            experience taught me to approach robotics projects from a more
            holistic system-level perspective.
          </p>
          <p>
            Furthering my journey, I participated in eYRC 2020-21, delving into
            ROS MoveIt!, MQTT IoT, Computer Vision, and website development. In
            May 2021, I played a pivotal role in the open-source project iq_gnc,
            enhancing Ardupilot drone developers' capabilities through code
            conversion and setting up a robust CI pipeline. This experience
            fortified my commitment to innovation and collaboration in the field
            of robotics.
          </p>
          <p>
            Beginning August 15th, 2021, I interned at RigBetal Labs LLP, as a
            ROS/Robotics Intern. My tasks included multi-robot mapping, cloud
            robotics, and Gazebo simulation with Blender. Building on past
            experience of creating novel algorithms, I crafted the Road Anomaly
            Detection System (R.A.D.S.) algorithm. This algorithm was designed
            for detecting road anomalies such as potholes, employs surface
            normal analysis and clustering. It determines surface normal at each
            point using normal estimation and identifies the common normal via
            RANSAC. A clustering algorithm then groups points with deviating
            normal, facilitating effective road anomaly detection.
          </p>
          <p>
            This project's novelty and success garnered me a full-time job
            offer. Notably, prompted by the client's request for a more
            budget-friendly solution than the initially costly 3D LiDAR, I
            proposed a cost-effective alternative: employing a rotating 2D LiDAR
            to emulate a 3D LiDAR. This innovation significantly reduced costs
            while preserving system efficiency and accuracy, underscoring my
            practical problem-solving abilities in the realm of robotics.
          </p>
        </div>
        <div class="ds-button-sec mt-4 text-center">
          <button class="ds-button ds-collapse-button" type="button" data-bs-toggle="collapse" data-bs-target="#aboutMe"
            aria-expanded="false" aria-controls="aboutMe" id="read-more-button">
            <span class="if-not-collapsed">Read More</span>
            <span class="if-collapsed">Read Less</span>
          </button>
        </div>
        <a href="#experience-section" class="d-none" id="navigate"></a>
      </section>
    </div>
  </div>
  <!-- about -->

  <!-- Education -->
  <div class="ds-experience-section" id="experience-section">
    <div class="container">
      <h2 class="ds-heading">Education</h2>
      <div class="row ds-experience-list">
        <div class="col-12 col-sm-12 col-md-6 col-lg-6 col-xl-6 col-xxl-6">
          <section>
            <span class="ds-year">September 2022 - May 2024</span>
            <h3 class="ds-officename">Northeastern University</h3>
            <span class="ds-department">Master of Science Robotics Engineering.</span>
            <span class="ds-department">GPA: 3.939</span>
            <p>Courses taken:</p>
            <ul>
              <li>EECE 7398 - Legged Robotics</li>
              <li>EECE 7323 - Numerical Optimization Methods</li>
              <li>MATH 7233 - Graph Theory</li>
              <li>EECE 7150 - Autonomous Field Robotics (Audit)</li>
              <li>ME 5250 - Robot Mechanics and Control</li>
              <li>EECE 5550 - Mobile Robotics</li>
              <li>CS 7150 - Deep Learning (Audit)</li>
              <li>EECE 5639 - Computer Vision</li>
              <li>CS 5180 - Reinforcement Learning and Decision Making</li>
              <li>EECE 5554 - Robotics Sensing and Navigation</li>
            </ul>
          </section>
        </div>
        <div class="col-12 col-sm-12 col-md-6 col-lg-6 col-xl-6 col-xxl-6">
          <section>
            <span class="ds-year">June 2018 - May 2022</span>
            <h3 class="ds-officename">Anna University</h3>
            <span class="ds-department">Bachelor of Engineering in Electrical and Electronics
              Engineering</span>
            <span class="ds-department">CGPA: 8.66/10.00</span>
            <p>Noteworthy Courses taken:</p>
            <ul>
              <li>Robotics and Machine Vision Systems</li>
              <li>Control Systems</li>
              <li>Data structures</li>
              <li>Embedded Systems</li>
              <li>Digital Signal Processing</li>
            </ul>
          </section>
        </div>
      </div>
    </div>
  </div>
  <!-- Education -->

  <!--  Work Experience -->
  <div class="ds-experience-section">
    <div class="container">
      <h2 class="ds-heading">Work Experience</h2>
      <div class="row ds-experience-list">
        <div class="col-12 col-sm-12 col-md-6 col-lg-6 col-xl-6 col-xxl-6">
          <section>
            <span class="ds-year">May 2024 - Present</span>
            <h3 class="ds-officename">
              <a target="_blank" href="https://robot.neu.edu/">Robotics and Intelligent Vehicles Research Laboratory
                (RIVeR)</a>
            </h3>
            <span class="ds-department">Robotics Research Assistant</span>
            <p><strong>Project:</strong> Stochastic Model Predictive Control for bipedal loco-manipulation</p>
            <ul>
              <li>Introduced probabilistic models into traditional MPC to create Stochastic MPC (SMPC), to improve
                adaptability and robustness against uneven terrain and unexpected loads</li>
              <li>Spearheaded the adaptation of the SMPC framework from quadrupedal to bipedal robots to demonstrate
                its generalizability, using simulation platforms such as PyBullet and Gazebo</li>
              <li>Refined the dynamics model and cost function to satisfy the constraints of the bipedal robot to
                guarantee stability</li>
            </ul>
          </section>
        </div>
        <div class="col-12 col-sm-12 col-md-6 col-lg-6 col-xl-6 col-xxl-6">
          <section>
            <span class="ds-year">January 2023 - May 2024</span>
            <h3 class="ds-officename">
              <a target="_blank" href="https://neu-autonomy.github.io/lab_website/">
                Northeastern Autonomy and Intelligence Laboratory (NAIL)
              </a>
            </h3>
            <span class="ds-department">Robotics Research Assistant</span>
            <p><strong>Project:</strong> High Speed Offroad Autonomy</p>
            <ul>
              <li>Developed an innovative 2.5D terrain model accommodating uncertainties in both the shape and
                properties of challenging off-road environment</li>
              <li>Created and Optimized a custom MPPI algorithm using JAX python, slashing average run time from
                <mark style="background-color: yellow;">1000 ms</mark> to
                <mark style="background-color: yellow;">1 ms</mark>
              </li>
              <li>Crafted a custom cost function for MPPI controls, prioritizing speed in unstructured environments
                while considering the robot's kino-dynamics, terrain traversability, and safety constraints</li>
              <li>Fine-tuned STEGO, a self-supervised semantic segmentation head for DINOv1 vision transformer, on RUGD,
                RELLIS, and a custom dataset to achieve clear class clusters for RGB image semantic segmentation</li>
              <li>Employed sensor fusion techniques to combine 3D-LiDAR data with semantically segmented RGB images,
                resulting in a Semantic Point Cloud, essential for downstream perception, control, and motion planning
                tasks</li>
              <li>Utilized Fusion 360 to engineer and assemble a customized compute and sensor suite payload, designed
                to meet the distinct needs of AgileX's scout and Clearpath's Warthog robotic platforms, to enable
                high-speed offroad autonomy capability</li>
              <!-- <li> -->
              <!--   Modified and Fine-tuned STEGO, a self-supervised semantic -->
              <!--   segmentation head, for DINOv1 vision transformer. -->
              <!--   <ul class="ms-4"> -->
              <!--     <li> -->
              <!--       Achieved clear class clusters for RGB image semantic -->
              <!--       segmentation -->
              <!--     </li> -->
              <!--     <li> -->
              <!--       Planned future incorporation of online learning in STEGO to -->
              <!--       increase robustness to unknown objects. -->
              <!--     </li> -->
              <!--   </ul> -->
              <!-- </li> -->
              <!-- <li> -->
              <!--   Employed sensor fusion techniques to combine 3D-LiDAR data -->
              <!--   with semantically segmented RGB images, resulting in a -->
              <!--   Semantic Point Cloud, essential for downstream perception, -->
              <!--   control and motion planning tasks. -->
              <!-- </li> -->
              <!-- <li> -->
              <!--   Improved the Direct LiDAR-Inertial Odometry (DLIO) algorithm -->
              <!--   to accept semantic point cloud as additional input, enabling -->
              <!--   the integration of semantic information derived from the -->
              <!--   vision transformer model. -->
              <!-- </li> -->
              <!-- <li> -->
              <!--   Developed a tailored navigation system encompassing -->
              <!--   representation, planning, and control components for operation -->
              <!--   in challenging, unstructured off-road terrain -->
              <!-- </li> -->
              <!-- <li> -->
              <!--   Implemented MPC and MPPI algorithms, incorporating tailored -->
              <!--   cost functions to ensure resilient planning and optimal -->
              <!--   control in challenging off-road terrains. -->
              <!-- </li> -->
              <!-- <li> -->
              <!--   Integrated SLAM (Simultaneous Localization and Mapping) and -->
              <!--   autonomous navigation algorithms, in both ROS1 and ROS2, -->
              <!--   enabling high-speed offroad autonomy capability in mobile -->
              <!--   robots. -->
              <!-- </li> -->
              <!-- <li> -->
              <!--   Utilized Fusion 360 to engineer and assemble a customized -->
              <!--   compute and sensor suite payload, designed to meet the -->
              <!--   distinct needs of AgileX's scout and Clearpath's Warthog -->
              <!--   robotic platforms, to enable high-speed offroad autonomy -->
              <!--   capability. -->
              <!-- </li> -->
            </ul>
          </section>
        </div>
        <div class="col-12 col-sm-12 col-md-6 col-lg-6 col-xl-6 col-xxl-6">
          <section>
            <span class="ds-year">August 2021 - November 2021</span>
            <h3 class="ds-officename">Rigbetal Labs LLP</h3>
            <span class="ds-department">Robotics Engineer, Intern</span>
            <ul>
              <li>Formulated a novel algorithm, Road Anomaly Detection System (RADS), in C++ to detect road anomalies
                (Potholes, Speed Bumps, etc.) using normal estimation</li>
              <li>Reduced cost by 90\%, by generating a 3D Point cloud from a series of moving 2D Laser scans</li>
              <li>Simulated a multi-agent (robot) mapping environment in Gazebo ROS to create a cohesive 2D map
                <ul>
                  <li>Deployed the same in a cloud environment using AWS Robomaker to enable remote multi-user control
                    of
                    an agents</li>
                </ul>
              </li>
              <!--   <li> -->
              <!--     Created a novel algorithm, Road Anomaly Detection System -->
              <!--     (RADS), in C++ to detect road anomalies (Potholes, Speed -->
              <!--     Bumps, etc.) using normal estimation -->
              <!--   </li> -->
              <!--   <li> -->
              <!--     Reduced cost by 90%, by generating a 3D Pointcloud from a -->
              <!--     series of moving 2D Laserscans -->
              <!--   </li> -->
              <!--   <li> -->
              <!--     Simulated a multi-agent (robot) mapping environment in Gazebo -->
              <!--     ROS to create a cohesive 2D map -->
              <!--   </li> -->
              <!--   <ul> -->
              <!--     <li> -->
              <!--       Tested viability of the same in a cloud environment (AWS -->
              <!--       Robomaker) to enable multi-user control of an agent -->
              <!--     </li> -->
              <!--   </ul> -->
            </ul>
          </section>
        </div>
        <div class="col-12 col-sm-12 col-md-6 col-lg-6 col-xl-6 col-xxl-6 mt-3">
          <section>
            <span class="ds-year"> July 2020 - December 2020</span>
            <h3 class="ds-officename">Capgemini Technologies Services</h3>
            <span class="ds-department">
              Robotics (Medical Devices), Intern
            </span>
            <ul>
              <li>Fabricated a ROS-based autonomous ground vehicle in Fusion 360 to sterilize and sanitize offices from
                SARS-COV2 virus with Ultraviolet (UV-C) irradiation </li>
              <li>Directed communication and task distribution between the team and clients, enhancing team efficiency
                and client relations.</li>
              <!--   <li> -->
              <!--     Designed in Fusion 360 a ROS-based autonomous ground vehicle -->
              <!--     to sterilize and sanitize offices from SARS-COV2 virus with -->
              <!--     Ultraviolet (UV-C) irradiation -->
              <!--   </li> -->
              <!--   <li> -->
              <!--     Managed Communications and task delegation between the team -->
              <!--     and the client -->
              <!--   </li> -->
            </ul>
          </section>
        </div>
      </div>
    </div>
  </div>
  <!--  Work Experience -->

  <!--  Skills -->
  <div class="ds-skills-section">
    <div class="container">
      <div class="row">
        <div class="col-12 col-sm-12 col-md-6 col-lg-6 col-xl-6 col-xxl-6">
          <h2 class="ds-heading">Languages and Libraries</h2>
          <ul class="ds-skills-list">
            <li>Python</li>
            <li>PyTorch</li>
            <li>C++</li>
            <li>C</li>
            <li>Matlab</li>
            <li>OpenCV</li>
            <li>Point Cloud Library</li>
            <li>Tensorflow</li>
            <li>Lua</li>
          </ul>
        </div>
        <div class="col-12 col-sm-12 col-md-6 col-lg-6 col-xl-6 col-xxl-6">
          <h2 class="ds-heading">Software and Tools</h2>
          <ul class="ds-skills-list">
            <li>ROS 1 & 2</li>
            <li>Ubuntu (Linux)</li>
            <li>Git</li>
            <li>CMake</li>
            <li>LaTeX</li>
            <li>Docker</li>
            <li>Gazebo</li>
            <li>Nvidia Issac Sim</li>
            <li>MQTT</li>
            <li>Simulink</li>
            <li>Fusion 360</li>
            <li>Blender</li>
            <li>OpenWRT</li>
            <li>Arduino</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
  <!--  Skills -->

  <!--  Work -->
  <div class="ds-work-section">
    <div class="container">
      <h2 class="ds-heading">Latest works</h2>
      <div class="ds-work-list-section">
        <div class="ds-work-list">
          <div class="row">
            <div class="col-12 col-sm-12 col-md-7 col-lg-7 col-xl-7 col-xxl-7">
              <section>
                <h3 class="ds-work-title">Batch Informed Trees</h3>
                <p>
                  Generally, we can divide the approximations used in path
                  planning into 2 types: Search-based and Sampling-based.
                </p>
                <p>
                  A recent approach called
                  <a target="_blank" class="ds-anchor"
                    href="https://journals.sagepub.com/doi/pdf/10.1177/0278364919890396">Batch Informed
                    Trees (BIT*)</a>
                  combines the strengths of both search-based and
                  sampling-based planners. In this work, we have used the
                  pseudo-code from the paper and coded the algorithm from
                  scratch, and tested its performance in R<sup>2</sup> space for
                  different motion planning scenarios using a custom
                  visualizer.
                </p>
                <a href="projects/BIT_star.html" target="_blank" class="ds-button">Details</a>
              </section>
            </div>
            <div class="col-12 col-sm-12 col-md-5 col-lg-5 col-xl-5 col-xxl-5 d-flex">
              <figure class="ds-image-container">
                <img src="assets/images/BIT_star/wall_gif.gif" />
              </figure>
            </div>
          </div>
        </div>
        <div class="ds-work-list">
          <div class="row">
            <div class="col-12 col-sm-12 col-md-7 col-lg-7 col-xl-7 col-xxl-7">
              <section>
                <h3 class="ds-work-tilte">
                  Learning Inverse Kinematics using Reinforcement Learning
                </h3>
                <p>
                  In this project, we present a Reinforcement Learning (RL)
                  approach to the problem of Inverse Kinematics (IK), which
                  involves controlling the end-effector of a 7 Degrees-of-
                  Freedom (DoF) robotic arm to enable it to reach a target
                  posi- tion. Our approach uses a policy gradient approach
                  with non- linear function approximators like neural
                  networks. Three major algorithms were investigated in this
                  research (DDPG, SAC and TD3 algorithms). In addition, we see
                  the effect of different reward structures in learning the
                  optimal policy for our chosen domain. We demonstrate the
                  effectiveness of our approach through experiments on a
                  simulated robotic arm, showing that our method is able to
                  learn a policy that can successfully control the arm to
                  reach the target position.
                </p>
                <a href="assets/pdfs/CS_5180_Final_Project_Report_Sahasrajit_Anuj_Kenechi.pdf" target="_blank"
                  class="ds-button">Report</a>
                <a href="https://github.com/Sahas-Ananth/RL-FinalProject" target="_blank"
                  class="ds-button ms-3">Code</a>
              </section>
            </div>
            <div class="col-12 col-sm-12 col-md-5 col-lg-5 col-xl-5 col-xxl-5 d-flex">
              <figure class="ds-image-container"><img src="assets/images/RL/DDPG_sbl.gif" /></figure>
            </div>
          </div>
        </div>
        <div class="ds-work-list">
          <div class="row">
            <div class="col-12 col-sm-12 col-md-7 col-lg-7 col-xl-7 col-xxl-7">
              <section>
                <h3 class="ds-work-tilte">
                  Intelligent Quads - Open Source Guidance, Navigation and
                  Control Project
                </h3>
                <p>
                  Intelligent Quads is a community dedicated to helping people
                  learn how to become developers of intelligent drone
                  applications.
                </p>
                <p>
                  The intelligent quads <code>gnc_functions</code> are
                  collection of high level functions to help make controlling
                  your drone simple. You can find functions for interpreting
                  state estimation, commanding waypoints, changing modes and
                  more. The documentation for using these functions is shown
                  <a href="https://github.com/Intelligent-Quads/iq_gnc/blob/master/docs/py_gnc_functions.md"
                    target="_blank">here</a>.
                </p>
                <a href="https://github.com/Intelligent-Quads/iq_gnc" target="_blank" class="ds-button">Code</a>
              </section>
            </div>
            <div class="col-12 col-sm-12 col-md-5 col-lg-5 col-xl-5 col-xxl-5 d-flex">
              <figure class="ds-image-container">
                <img src="assets/images/IQ_quads/IQ-GitHub-Banner.png" />
              </figure>
            </div>
          </div>
        </div>
        <div class="ds-work-list">
          <div class="row">
            <div class="col-12 col-sm-12">
              <section class="pe-0">
                <h3 class="ds-work-tilte">
                  Vargi Bots - e-Yantra (Finalist)
                </h3>
                <p>
                  Inspired by Industry 4.0 principles, the e-Yantra Robotics
                  Competition's latest edition showcases 'Vargi-Bots.' This
                  theme centers on an automated warehouse management system
                  within the Gazebo simulator, using ROS as a middleware. The
                  setup includes two industrial robotic arms responsible for
                  sorting and dispatching essential packages to various city
                  locations. Notably, high-priority packages, such as those
                  needed for emergencies, are given priority. Participants are
                  challenged to design a smart controller to optimize the
                  delivery process. The updates are sent out using MQTT in
                  Python and are trackable in Google Sheets, which is
                  automated through the Google Sheets API controlled using
                  Python.
                </p>
                <a href="https://github.com/Sahas-Ananth/Vargi_Bot_Eyantra" target="_blank" class="ds-button">Code</a>
              </section>
            </div>
            <!-- <div -->
            <!--   class="col-12 col-sm-12 col-md-5 col-lg-5 col-xl-5 col-xxl-5" -->
            <!-- > -->
            <!--   <figure> -->
            <!--     <img src="assets/images/IQ_quads/IQ-GitHub-Banner.png" /> -->
            <!--   </figure> -->
            <!-- </div> -->
          </div>
        </div>
      </div>
    </div>
  </div>
  <!--  Work -->

  <!--  footer -->
  <footer class="ds-footer text-center">
    <div class="container">
      <section>
        <span>Stay in touch</span>
        <h4>Ready to talk?</h4>
        <p>Feel free to contact me!</p>
        <a href="mailto:anantharamakrishn.sa@northeastern.edu" class="ds-button">Lets Talk</a>
        <ul class="ds-social justify-content-center mt-4 mb-0">
          <li>
            <a href="https://github.com/Sahas-Ananth" target="_blank">
              <i class="ri-github-fill"></i>
            </a>
          </li>
          <li>
            <a href="mailto:anantharamakrishn.sa2northeastern.edu" target="_blank"><i class="ri-mail-fill"></i></a>
          </li>
          <li>
            <a href="https://www.linkedin.com/in/sahas-ananth/" target="_blank"><i class="ri-linkedin-fill"></i></a>
          </li>
        </ul>
      </section>
      <span class="ds-copyright">Â© 2022 All rights reserved. Free minimal bootstrap template by
        <a href="https://designstub.com/" target="_blank">Designstub</a>. <br />Edited by <a class="ds-anchor"
          href="https://saravanankish.github.io">Saravanan K</a>.</span>

    </div>
  </footer>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <!-- Option 1: Bootstrap Bundle with Popper -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
    crossorigin="anonymous"></script>

  <!-- Option 2: Separate Popper and Bootstrap JS -->
  <!--
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.9.2/dist/umd/popper.min.js" integrity="sha384-IQsoLXl5PILFhosVNubq5LC7Qb9DXgDA9i+tQ8Zj3iwWAwPtgFTxbJ8NT4GN1R8p" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.min.js" integrity="sha384-cVKIPhGWiC2Al4u+LWgxfKTRIcfu0JTxR+EQDz/bgldoEyl4H0zUF0QKbrJ0EcQF" crossorigin="anonymous"></script>
    -->
  <script src="assets/js/main.js"></script>
</body>

</html>
